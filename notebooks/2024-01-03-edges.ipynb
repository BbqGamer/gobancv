{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def imshow(img, size=(5, 5)):\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    plt.rcParams['figure.figsize'] = size\n",
    "    plt.imshow(img)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.show()\n",
    "\n",
    "IMAGE_PATH = \"../data/static/\"\n",
    "\n",
    "imgs = [cv.imread(IMAGE_PATH + img) for img in os.listdir(IMAGE_PATH) if img.split('.')[-1] in ['jpg', 'jpeg', 'png']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    sharrx = cv.Scharr(gray, cv.CV_8U, 1, 0)\n",
    "    sharry = cv.Scharr(gray, cv.CV_8U, 0, 1)\n",
    "    mag_sharr, angle_sharr = cv.cartToPolar(sharrx.astype('float32'), sharry.astype('float32'), angleInDegrees=True)\n",
    "    mag_sharr_norm = cv.normalize(mag_sharr, None, 0, 255, cv.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "    sobelx = cv.Sobel(gray, cv.CV_8U, 1, 0)\n",
    "    sobely = cv.Sobel(gray, cv.CV_8U, 0, 1)\n",
    "    mag_sob, angle_sob = cv.cartToPolar(sobelx.astype('float32'), sobely.astype('float32'), angleInDegrees=True)\n",
    "    mag_sob_norm = cv.normalize(mag_sob, None, 0, 255, cv.NORM_MINMAX).astype(np.uint8)\n",
    "    \n",
    "    imshow(img)\n",
    "    imshow(np.concatenate([\n",
    "        np.concatenate([sharrx, sharry, mag_sharr_norm], axis=1),\n",
    "        np.concatenate([sobelx, sobely, mag_sob_norm], axis=1)],\n",
    "        axis=0\n",
    "    ), size=(30,11))\n",
    "\n",
    "for img in imgs:\n",
    "    process_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly edge detection seems to work better with sobel than with sharr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see speed of this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 100\n",
    "gray = cv.cvtColor(imgs[0], cv.COLOR_BGR2GRAY)\n",
    "sobelx = cv.Sobel(gray, cv.CV_8U, 1, 0)\n",
    "sobely = cv.Sobel(gray, cv.CV_8U, 0, 1)\n",
    "mag_sob, angle_sob = cv.cartToPolar(sobelx.astype('float32'), sobely.astype('float32'), angleInDegrees=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny(img):\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    edges = cv.Canny(gray, 100, 300, apertureSize=3)\n",
    "    imshow(np.concatenate([gray, edges], axis=1), size=(30,11))\n",
    "\n",
    "for img in imgs:\n",
    "    canny(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom filter\n",
    "Try to focus on thin lines. \\\n",
    "Let's see what happens after applying sobel on both positive and negative directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv.cvtColor(imgs[2], cv.COLOR_BGR2GRAY)\n",
    "\n",
    "sobel_kernel = np.array([\n",
    "    [-1, 0, 1],\n",
    "    [-2, 0, 2],\n",
    "    [-1, 0, 1]\n",
    "])\n",
    "cut = gray[400:500, 500:600]\n",
    "down = cv.filter2D(cut, cv.CV_8U, sobel_kernel.T) # compues gradient in positive y direction\n",
    "up = cv.filter2D(cut, cv.CV_8U, np.flip(sobel_kernel.T)) # compues gradient in negative y direction\n",
    "imshow(np.concatenate([cut, down, up], axis=1), size=(30, 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thin objects (like lines) will have high values near to each other in both directions. \\\n",
    "Let's use thresholding, dilation and logical AND to get only those pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thup = cv.threshold(up, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)[1]\n",
    "thdown = cv.threshold(down, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)[1]\n",
    "dup = cv.dilate(thup, np.ones((3,3), np.uint8))\n",
    "ddown = cv.dilate(thdown, np.ones((3,3), np.uint8))\n",
    "AND = cv.bitwise_and(dup, ddown)\n",
    "imshow(np.concatenate([thup, thdown], axis=1), size=(10, 11))\n",
    "imshow(np.concatenate([dup, ddown, AND], axis=1), size=(30, 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see most stones are gone, but some are still there.\n",
    "Let's how this works if we apply it on a whole image and both horizontally and vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_filter(gray):\n",
    "    def line_filter_aux(img, kernel):\n",
    "        down = cv.filter2D(gray, cv.CV_8U, kernel)\n",
    "        up = cv.filter2D(gray, cv.CV_8U, np.flip(kernel))\n",
    "        thup = cv.threshold(up, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)[1]\n",
    "        thdown = cv.threshold(down, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)[1]\n",
    "        dup = cv.dilate(thup, np.ones((3,3), np.uint8))\n",
    "        ddown = cv.dilate(thdown, np.ones((3,3), np.uint8))\n",
    "        AND = cv.bitwise_and(dup, ddown)\n",
    "        return AND\n",
    "\n",
    "    sobel_kernel = np.array([\n",
    "        [-1, 0, 1],\n",
    "        [-2, 0, 2],\n",
    "        [-1, 0, 1]\n",
    "    ])\n",
    "\n",
    "    a = line_filter_aux(gray, sobel_kernel.T)\n",
    "    b = line_filter_aux(gray, sobel_kernel)\n",
    "    AND = cv.bitwise_and(a, b) \n",
    "    OR = cv.bitwise_or(a, b)\n",
    "    return AND, OR\n",
    "\n",
    "for img in imgs:\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    AND, OR = line_filter(gray)\n",
    "    imshow(np.concatenate([gray, AND, OR]), size=(30, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My idea was to use logical OR to get all intersections of lines, however it doesn't necessarily work good on all images. \\\n",
    "We will stick with using **AND** for now and try to use it to segment the board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 100\n",
    "line_filter(gray)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
